{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b8c886",
   "metadata": {},
   "source": [
    "## Tutorial \\#2: Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd51e1e",
   "metadata": {},
   "source": [
    "<b><i>Spark</i></b>, is built on top of Jax and the one of the core features of Jax is Just-In-Time compilation, or JIT for short. JIT is extremely good at optimizing how your code executes. Therefore, it is important to have a minimum understanding of how to play with JIT. So, let's start with a simple JIT example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ddc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 ms ± 304 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Some really cool function\n",
    "def my_awesome_function(x, y):\n",
    "    return x * y + x**2\n",
    "\n",
    "# Two random arrays\n",
    "rng = jax.random.key(42)\n",
    "key_x, key_y = jax.random.split(rng, 2)\n",
    "x = jax.random.uniform(key_x, shape=(4096,4096), dtype=jnp.float32)\n",
    "y = jax.random.uniform(key_y, shape=(4096,4096), dtype=jnp.float32)\n",
    "\n",
    "# Test it!\n",
    "%timeit my_awesome_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb83e8a",
   "metadata": {},
   "source": [
    "Now, this is fast, but can it be better?\n",
    "\n",
    "Let's JIT the funtion and run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a33089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529 μs ± 130 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Some really cool and fast function\n",
    "@jax.jit\n",
    "def my_awesome_function(x, y):\n",
    "    return x * y + x**2\n",
    "\n",
    "%timeit my_awesome_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33096a59",
   "metadata": {},
   "source": [
    "Note that, JIT as its name suggest, compiles the code just before running it, this leads to longer execution times the first the function is executed. Depending on the code being JITted this can lead to really long compilation times, for example, it is possible to compile and entire for loop that executes thousands of operations in total (note that this is not recommended but may be a useful trick depending on the circumstances). \n",
    "\n",
    "Unfortunately, it is slightly more complicated in <b><i>Spark</i></b> (but do not worry, it is not that complicated!).\n",
    "\n",
    "Under the hood Jax unfolds the computation graph and tries to optimize it, this however is not trivial when you have to do some state management. In <b><i>Spark</i></b> we borrow one of the core element of Flax, an excellent machine learning library, that allow us to not care to much about state management at the expense of a slightly more complicated JIT execution. Although this may change as <b><i>Spark</i></b> matures, right now this is the standard approach to execute your code.\n",
    "\n",
    "Let's start by initializing some simple ALIF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "698210e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh no!, alif_neurons do not have a soma property.\n",
      "\n",
      "{'out_spikes': SpikeArray(value=Array([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -0.], dtype=float16))} \n",
      "\n",
      "Those are some nice somas!.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import spark\n",
    "\n",
    "# Number of neurons\n",
    "units = (8,)\n",
    "\n",
    "# Input shape\n",
    "input_shape = (16,)\n",
    "\n",
    "# Model initialization\n",
    "alif_neurons = spark.nn.neurons.ALIFNeuron(\n",
    "    units=units,\n",
    "\tmax_delay=4,\n",
    "\tinhibitory_rate=0.2,\n",
    "\t_s_async_spikes=True,\n",
    "    _s_units=units,\n",
    ")\n",
    "\n",
    "# Test the model.\n",
    "rng = jax.random.key(42)\n",
    "rng, key = jax.random.split(rng, 2)\n",
    "in_spikes = spark.SpikeArray( \n",
    "    jax.random.uniform(key, shape=input_shape, dtype=jnp.float16) < 0.5 \n",
    ")\n",
    "\n",
    "# Note that the model the first time is called.\n",
    "try:\n",
    "    alif_neurons.soma\n",
    "    print('Those are some nice somas!.\\n')\n",
    "except:\n",
    "    print('Oh no!, alif_neurons do not have a soma property.\\n')\n",
    "\n",
    "# First call to alif_neurons \n",
    "out_spikes = alif_neurons(in_spikes=in_spikes)\n",
    "print(out_spikes, '\\n')\n",
    "\n",
    "# Now the soma property exists.\n",
    "try:\n",
    "    alif_neurons.soma\n",
    "    print('Those are some nice somas!.')\n",
    "except:\n",
    "    print('Oh no!, alif_neurons do not have a soma property.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13636993",
   "metadata": {},
   "source": [
    "Similarly, to the cases above, we need to wrap the execution of our code inside a function that we can then compile. Although we can pass directly our model and it will run, you will soon realize that its state remains unchanged, this is the standard behaviour of JIT, we need to let JIT know what is the compuational graph and what is the state of that graph explicitly.\n",
    "\n",
    "To separate the logic of our model into a graph and an state we can use <b>spark.split</b> and to glue it back for execution we use <b>spark.merge</b>. Note that currently this is just a convinience wrapper arounds Flax's nnx.split and nnx.merge, respectively, although it may change in the future. That's it, this is as much as JIT as you need to know. Just remember, when you define your own models use <b>spark.Constant</b>  and <b>spark.Variable</b> to wrap your code, otherwise JIT is going to complain!.\n",
    "\n",
    "As a small observation, note that we feed everything to the model with <b>**inputs</b> since the <b>\\_\\_call\\_\\_</b> method only allows for keyworded arguments (which can still be received by position). This could be really advantageous when we encounter models that have more than one input stream or we have many different models that we want to try since it allows us to create code that is more reusable and flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9722557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_spikes': SpikeArray(value=Array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float16))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JITted function for execution\n",
    "@jax.jit\n",
    "def run_model(graph, state, **inputs):\n",
    "\tmodel = spark.merge(graph, state)\t# Merge the graph and the state into a single executable model equivalent to ALIFNeuron.\n",
    "\toutputs = model(**inputs)\n",
    "\t_, state = spark.split((model))\t\t# Split the model back into a graph and a state. Here we are discarding the graph since typically it doesn't change.\n",
    "\treturn outputs, state\n",
    "\n",
    "# Execution\n",
    "graph, state = spark.split((alif_neurons))\t# <-- Note that model is inside another parenthesis, this will be important for more complex cases.\n",
    "outputs, state = run_model(graph, state, in_spikes=in_spikes)\t# Note that we overwrite the state after the execution.\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe332a",
   "metadata": {},
   "source": [
    "This is basically all you need to know to get the most out of <b><i>Spark</i></b>!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
