{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b513e5cb",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-header\">\n",
    "\n",
    "## Tutorial \\#2: Execution\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd51e1e",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "<b><i>Spark</i></b>, is built on top of Jax and the one of the core features of Jax is Just-In-Time compilation, or JIT for short. JIT is extremely good at optimizing how your code executes. Therefore, it is important to have a minimum understanding of how to play with JIT. So, let's start with a simple JIT example.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ddc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 ms ± 308 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Some really cool function\n",
    "def my_awesome_function(x, y):\n",
    "    return x * y + x**2\n",
    "\n",
    "# Two random arrays\n",
    "rng = jax.random.key(42)\n",
    "key_x, key_y = jax.random.split(rng, 2)\n",
    "x = jax.random.uniform(key_x, shape=(4096,4096), dtype=jnp.float32)\n",
    "y = jax.random.uniform(key_y, shape=(4096,4096), dtype=jnp.float32)\n",
    "\n",
    "# Test it!\n",
    "%timeit my_awesome_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb83e8a",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "Now, this is fast, but can it be better?\n",
    "\n",
    "Let's JIT the funtion and run it again.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a33089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528 μs ± 302 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Some really cool and fast function\n",
    "@jax.jit\n",
    "def my_awesome_function(x, y):\n",
    "    return x * y + x**2\n",
    "\n",
    "%timeit my_awesome_function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33096a59",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "Note that, JIT as its name suggest, compiles the code just before running it, this leads to longer execution times the first the function is executed. Depending on the code being JITted this can lead to really long compilation times, for example, it is possible to compile and entire for loop that executes thousands of operations in total (note that this is not recommended but may be a useful trick depending on the circumstances). \n",
    "\n",
    "Unfortunately, it is slightly more complicated in <b><i>Spark</i></b> (but do not worry, it is not that complicated!).\n",
    "\n",
    "Under the hood Jax unfolds the computation graph and tries to optimize it, this however is not trivial when you have to do some state management. In <b><i>Spark</i></b> we borrow one of the core element of Flax, an excellent machine learning library, that allow us to not care to much about state management at the expense of a slightly more complicated JIT execution. Although this may change as <b><i>Spark</i></b> matures, right now this is the standard approach to execute your code.\n",
    "\n",
    "Let's start by initializing some simple ALIF model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698210e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh no!, alif_neurons do not have a soma property.\n",
      "\n",
      "{'out_spikes': SpikeArray(value=Array([ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.], dtype=float16))} \n",
      "\n",
      "Those are some nice somas!.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import spark\n",
    "\n",
    "# Number of neurons\n",
    "units = (8,)\n",
    "\n",
    "# Input shape\n",
    "input_shape = (16,)\n",
    "\n",
    "# Model initialization\n",
    "alif_neurons = spark.nn.neurons.ALIFNeuron(\n",
    "    units=units,\n",
    "\tmax_delay=4,\n",
    "\tinhibitory_rate=0.2,\n",
    "\t_s_async_spikes=True,\n",
    "    _s_units=units,\n",
    ")\n",
    "\n",
    "# Test the model.\n",
    "rng = jax.random.key(42)\n",
    "rng, key = jax.random.split(rng, 2)\n",
    "in_spikes = spark.SpikeArray( \n",
    "    jax.random.uniform(key, shape=input_shape, dtype=jnp.float16) < 0.5 \n",
    ")\n",
    "\n",
    "# Note that the model the first time is called.\n",
    "try:\n",
    "    alif_neurons.soma\n",
    "    print('Those are some nice somas!.\\n')\n",
    "except:\n",
    "    print('Oh no!, alif_neurons do not have a soma property.\\n')\n",
    "\n",
    "# First call to alif_neurons \n",
    "out_spikes = alif_neurons(in_spikes=in_spikes)\n",
    "print(out_spikes, '\\n')\n",
    "\n",
    "# Now the soma property exists.\n",
    "try:\n",
    "    alif_neurons.soma\n",
    "    print('Those are some nice somas!.')\n",
    "except:\n",
    "    print('Oh no!, alif_neurons do not have a soma property.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13636993",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "Similarly, to the cases above, we just need to wrap the execution of the model inside a function that we can then compile. Remember that the first time the function is executed it can take a little bit more time (important if you want to benchmark your own models!).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9902c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 μs ± 7.46 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# JITted function for execution\n",
    "@jax.jit\n",
    "def run_model(model, **inputs):\n",
    "\toutputs = model(**inputs)\n",
    "\treturn outputs, model\t\t# <-- Return and replace the model. Otherwise the model will not change\n",
    "\n",
    "# Execution\n",
    "outputs, alif_neurons = run_model(alif_neurons, in_spikes=in_spikes) # Note that we overwrite the model after the execution.\n",
    "\n",
    "%timeit run_model(alif_neurons, in_spikes=in_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8635e3",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "Although we can feed directly our model to JAX and it will execute fine and fast, it is almost always faster to split the model into a graph and a state (quirks of the code ¯\\\\_(ツ)_/¯).\n",
    "\n",
    "To separate the logic of our model into a graph and an state we can use <b>spark.split</b> and to glue it back for execution we use <b>spark.merge</b>. Note that currently this is just a convinience wrapper arounds Flax's nnx.split and nnx.merge, respectively, although it may change in the future. That's it, this is as much as JIT as you need to know. Just remember, when you define your own models use <b>spark.Constant</b>  and <b>spark.Variable</b> to wrap your code, otherwise JIT is going to complain!.\n",
    "\n",
    "As a small observation, note that we feed everything to the model with <b>**inputs</b> since the <b>\\_\\_call\\_\\_</b> method only allows for keyworded arguments (which can still be received by position). This could be really advantageous when we encounter models that have more than one input stream or we have many different models that we want to try since it allows us to create code that is more reusable and flexible.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9722557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.8 μs ± 3.18 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# JITted function for execution\n",
    "@jax.jit\n",
    "def run_model_split(graph, state, **inputs):\n",
    "\tmodel = spark.merge(graph, state)\t# Merge the graph and the state into a single executable model equivalent to ALIFNeuron.\n",
    "\toutputs = model(**inputs)\n",
    "\t_, state = spark.split((model))\t\t# Split the model back into a graph and a state. Here we are discarding the graph since typically it doesn't change.\n",
    "\treturn outputs, state\n",
    "\n",
    "# Execution\n",
    "graph, state = spark.split((alif_neurons))\t# <-- Note that model is inside another parenthesis, this will be important for more complex cases.\n",
    "outputs, state = run_model_split(graph, state, in_spikes=in_spikes)\t# Note that we overwrite the state after the execution.\n",
    "\n",
    "%timeit run_model_split(graph, state, in_spikes=in_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe332a",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./style.css\">\n",
    "\n",
    "<div class=\"tutorial-text\">\n",
    "\n",
    "This is basically all the JAX & JIT you need to know to get the most out of <b><i>Spark</i></b>!\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
